<img src="https://github.com/diambra/agents/blob/main/img/agents.jpg?raw=true" alt="diambra" width="100%"/>

<p align="center">
  <a href="https://docs.diambra.ai">Documentation</a> •
  <a href="https://diambra.ai/">Website</a>
</p>
<p align="center">
  <a href="https://www.linkedin.com/company/diambra">Linkedin</a> •
  <a href="https://diambra.ai/discord">Discord</a> •
  <a href="https://www.twitch.tv/diambra_ai">Twitch</a> •
  <a href="https://www.youtube.com/c/diambra_ai">YouTube</a> •
  <a href="https://twitter.com/diambra_ai">Twitter</a>
</p>

# A collection of Agents interfaced with DIAMBRA Arena

This repository contains many examples of Agents that interact with <a href="https://github.com/diambra/arena">DIAMBRA Arena</a>, our exclusive suite of Reinforcement Learning environments. They show how to use the standard OpenAI Gym API, and how to interface it with the most widely used state-of-the-art RL libraries.

They are divided in the following categories:
- <a href="https://github.com/diambra/agents/tree/main/basic">Basic (No-Op, Random)</a>
- <a href="https://github.com/diambra/agents/tree/main/stable_baselines3">Stable-Baselines 3</a>
- <a href="https://github.com/diambra/agents/tree/main/ray_rllib">Ray RLlib</a>
- <a href="https://github.com/diambra/agents/tree/main/stable_baselines">Stable-Baselines (Deprecated)</a>

Take a look at the dedicated section of our <a href="https://docs.diambra.ai/handsonreinforcementlearning/#end-to-end-deep-reinforcement-learning">Documentation</a> to know more!

###### DIAMBRA, Inc. © Copyright 2018-2023. All Rights Reserved.

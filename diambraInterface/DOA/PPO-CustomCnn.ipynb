{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameFolder = \"DOA++-MAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import time\n",
    "timeDepSeed = int((time.time()-int(time.time()-0.5))*1000)\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../'))   \n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../../../games',gameFolder))   \n",
    "\n",
    "tensorBoardFolder = \"./ppo2_TB_CustCnn/\"\n",
    "modelFolder = \"ppo2_Model_CustCnn/\"\n",
    "\n",
    "os.makedirs(modelFolder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makeDiambraEnv import *\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from customPolicies.utils import linear_schedule, AutoSave\n",
    "from customPolicies.customCnnPolicy import *\n",
    "\n",
    "from stable_baselines import PPO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexpalms/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "Env_id =  Train0\n",
      "Continue value =  0\n",
      "1P Environment\n",
      "Player side = Random , Character = Kasumi\n",
      "Using frame stacking with dilation =  6\n",
      "Env_id =  Train1\n",
      "Continue value =  0\n",
      "Failed to open, retrying ... \n",
      "1P Environment\n",
      "Player side = Random , Character = Kasumi\n",
      "Using frame stacking with dilation =  6\n",
      "Env_id =  Train2\n",
      "Continue value =  0\n",
      "Failed to open, retrying ... \n",
      "1P Environment\n",
      "Player side = Random , Character = Kasumi\n",
      "Using frame stacking with dilation =  6\n",
      "Env_id =  Train3\n",
      "Continue value =  0\n",
      "1P Environment\n",
      "Player side = Random , Character = Kasumi\n",
      "Using frame stacking with dilation =  6\n",
      "Env_id =  Train4\n",
      "Continue value =  0\n",
      "Failed to open, retrying ... \n",
      "1P Environment\n",
      "Player side = Random , Character = Kasumi\n",
      "Using frame stacking with dilation =  6\n",
      "Env_id =  Train5\n",
      "Continue value =  0\n",
      "1P Environment\n",
      "Player side = Random , Character = Kasumi\n",
      "Using frame stacking with dilation =  6\n",
      "Env_id =  Train6\n",
      "Continue value =  0\n",
      "Failed to open, retrying ... \n",
      "1P Environment\n",
      "Player side = Random , Character = Kasumi\n",
      "Using frame stacking with dilation =  6\n",
      "Env_id =  Train7\n",
      "Continue value =  0\n",
      "1P Environment\n",
      "Player side = Random , Character = Kasumi\n",
      "Using frame stacking with dilation =  6\n"
     ]
    }
   ],
   "source": [
    "diambraKwargs = {}\n",
    "diambraKwargs[\"roms_path\"] = \"../../../roms/MAMEToolkit/roms/\"\n",
    "diambraKwargs[\"binary_path\"] = \"../../../../customMAME/\"\n",
    "diambraKwargs[\"player\"] = \"Random\"\n",
    "diambraKwargs[\"frame_ratio\"] = 1\n",
    "diambraKwargs[\"render\"] = False\n",
    "diambraKwargs[\"characters\"] = [\"Kasumi\"]\n",
    "\n",
    "wrapperKwargs = {}\n",
    "wrapperKwargs[\"hwc_obs_resize\"] = [256, 256, 1]\n",
    "wrapperKwargs[\"normalize_rewards\"] = True\n",
    "wrapperKwargs[\"clip_rewards\"] = False\n",
    "wrapperKwargs[\"frame_stack\"] = 6\n",
    "wrapperKwargs[\"dilation\"] = 6\n",
    "wrapperKwargs[\"scale\"] = True\n",
    "wrapperKwargs[\"scale_mod\"] = 0\n",
    "\n",
    "\n",
    "#keyToAdd = None\n",
    "keyToAdd = []\n",
    "keyToAdd.append(\"actionsBufP1\") # env.actBufLen*(env.n_actions[0]+env.n_actions[1])\n",
    "keyToAdd.append(\"ownHealth\")    # 1\n",
    "keyToAdd.append(\"oppHealth\")    # 1\n",
    "keyToAdd.append(\"ownPosition\")  # 1\n",
    "keyToAdd.append(\"ownPosition\")  # 1\n",
    "keyToAdd.append(\"stage\")        # 1\n",
    "keyToAdd.append(\"characters\")   # 2*len(env.charNames)\n",
    "\n",
    "numEnv=8\n",
    "\n",
    "env = make_diambra_env(diambraMame, env_prefix=\"Train\", num_env=numEnv, seed=timeDepSeed, \n",
    "                       continue_game=0, diambra_kwargs=diambraKwargs, \n",
    "                       wrapper_kwargs=wrapperKwargs, key_to_add=keyToAdd)\n",
    "\n",
    "envRef = env.envs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs_space =  Box(256, 256, 7)\n",
      "Obs_space type =  float32\n",
      "Obs_space high =  [[[1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]]]\n",
      "Obs_space low =  [[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Obs_space = \", env.observation_space)\n",
    "print(\"Obs_space type = \", env.observation_space.dtype)\n",
    "print(\"Obs_space high = \", env.observation_space.high)\n",
    "print(\"Obs_space low = \", env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Act_space =  MultiDiscrete([9 8])\n",
      "Act_space type =  int64\n",
      "Act_space n =  [9 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"Act_space = \", env.action_space)\n",
    "print(\"Act_space type = \", env.action_space.dtype)\n",
    "print(\"Act_space n = \", env.action_space.nvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy param\n",
    "policyKwargs={}\n",
    "policyKwargs[\"n_add_info\"] = envRef.actBufLen*(envRef.n_actions[0]+envRef.n_actions[1]) + len(keyToAdd)-2 # No Char Info\n",
    "policyKwargs[\"layers\"] = [64, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexpalms/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alexpalms/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alexpalms/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alexpalms/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alexpalms/Work/ArtificialTwin/Diambra/diambraengine_multiDiscrete/stableBaselines/diambraInterface/DOA/../customPolicies/customCnnPolicy.py:31: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1bfb1a2fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1bfb1a2fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1bfb1a2fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1bfb1a2fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1bf84dfda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1bf84dfda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1bf84dfda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1bf84dfda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/alexpalms/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alexpalms/anaconda3/envs/diambra/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/alexpalms/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alexpalms/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PPO param\n",
    "setGamma = 0.94\n",
    "setLearningRate = linear_schedule(2.5e-4, 2.5e-6)\n",
    "setClipRange = linear_schedule(0.2, 0.025)\n",
    "setClipRangeVf = setClipRange\n",
    "\n",
    "# Initialize the model, 1 env\n",
    "#model = PPO2(CustCnnPolicy, env, verbose=1, \n",
    "#             gamma = setGamma, nminibatches=4, noptepochs=4, n_steps=128,\n",
    "#             learning_rate=setLearningRate, cliprange=setClipRange, cliprange_vf=setClipRangeVf, \n",
    "#             tensorboard_log=tensorBoardFolder, policy_kwargs=policyKwargs)\n",
    "\n",
    "#OR\n",
    "\n",
    "# Load the trained agent\n",
    "model = PPO2.load(modelFolder+\"13_5M\", env=env, tensorboard_log=tensorBoardFolder, \n",
    "                  policy_kwargs=policyKwargs, gamma = setGamma, learning_rate=setLearningRate, \n",
    "                  cliprange=setClipRange, cliprange_vf=setClipRangeVf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model discount factor = \", model.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the callback: autosave every USER DEF steps\n",
    "autoSaveCallback = AutoSave(check_freq=1000000, numEnv=numEnv, save_path=modelFolder+\"13_5M_\")\n",
    "\n",
    "# Train the agent\n",
    "time_steps = 30000000\n",
    "model.learn(total_timesteps=time_steps, callback=autoSaveCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the agent\n",
    "model.save(modelFolder+\"33_5M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new evaluation environment\n",
    "diambraKwargs[\"render\"] = True\n",
    "\n",
    "env = make_diambra_env(diambraMame, env_prefix=\"Eval\", num_env=1, seed=timeDepSeed, \n",
    "                       continue_game=0, diambra_kwargs=diambraKwargs, \n",
    "                       wrapper_kwargs=wrapperKwargs, key_to_add=keyToAdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "cumulativeEpRew = 0.0\n",
    "cumulativeEpRewAll = []\n",
    "cumulativeTotRew = 0.0\n",
    "\n",
    "maxNumEp = 100\n",
    "currNumEp = 0\n",
    "\n",
    "while currNumEp < maxNumEp:\n",
    "\n",
    "    action = model.predict(observation, deterministic=False)\n",
    "    #action_prob = model.action_probability(observation, states)\n",
    "    #print(\"Action probabilities = \", action_prob)\n",
    "    #print(\"Max action = \", np.argmax(action_prob))\n",
    "    #print(\"Action = \", action)\n",
    "    \n",
    "    observation, reward, done, info = env.step(action[0])\n",
    "    \n",
    "    cumulativeEpRew += reward\n",
    "    \n",
    "    if np.any(done):\n",
    "        currNumEp += 1\n",
    "        print(\"Ep. # = \", currNumEp)\n",
    "        print(\"Ep. Cumulative Rew # = \", cumulativeEpRew)\n",
    "        cumulativeEpRewAll.append(cumulativeEpRew)\n",
    "        cumulativeTotRew += cumulativeEpRew\n",
    "        cumulativeEpRew = 0.0\n",
    "\n",
    "print(\"Mean cumulative reward = \", cumulativeTotRew/maxNumEp)    \n",
    "print(\"Mean cumulative reward = \", np.mean(cumulativeEpRewAll))    \n",
    "print(\"Std cumulative reward = \", np.std(cumulativeEpRewAll))   \n",
    "    \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

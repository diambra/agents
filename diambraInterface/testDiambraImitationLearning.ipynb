{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "import pickle, bz2 \n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../../utils'))\n",
    "\n",
    "from diambraImitationLearning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diambraIL_kwargs = {}\n",
    "diambraIL_kwargs[\"hwc_dim\"] = [256,256,7]\n",
    "diambraIL_kwargs[\"n_actions\"] = [9, 8]\n",
    "diambraIL_kwargs[\"trajFilesList\"] = [\"./RLTraj_2020-09-04_00-16-24\"] # P1\n",
    "#diambraIL_kwargs[\"trajFilesList\"] = [\"./RLTraj_2020-09-04_00-08-44\"] # P1P2\n",
    "diambraIL_kwargs[\"totalCpus\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_diambra_imitationLearning_env(diambraImitationLearning, diambraIL_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.env_method(\"trajSummary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nChars = env.get_attr(\"nChars\")[0]\n",
    "n_actions = env.get_attr(\"n_actions\")[0]\n",
    "actBufLen = env.get_attr(\"actBufLen\")[0]\n",
    "playerId = env.get_attr(\"playerId\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = observation.shape\n",
    "\n",
    "additionalPar = int(observation[0,0,shp[2]-1])\n",
    "# 1P\n",
    "nScalarAddPar = additionalPar - 2*nChars - actBufLen*(n_actions[0]+n_actions[1])\n",
    "\n",
    "print(\"Additional Par = \", additionalPar)\n",
    "print(\"N scalar actions = \", nScalarAddPar)\n",
    "\n",
    "cumulativeEpRew = 0.0\n",
    "cumulativeEpRewAll = []\n",
    "\n",
    "maxNumEp = 10\n",
    "currNumEp = 0\n",
    "\n",
    "procIdx = 0\n",
    "\n",
    "while currNumEp < maxNumEp:\n",
    "       \n",
    "    dummy_actions = [0 for i in range(diambraIL_kwargs[\"totalCpus\"])]\n",
    "    observation, reward, done, info = env.step(dummy_actions)\n",
    "    \n",
    "    observation = observation[procIdx]\n",
    "    reward = reward[procIdx]\n",
    "    done = done[procIdx]\n",
    "    action = info[procIdx][\"action\"]\n",
    "    #print(\"Action:\", action)\n",
    "    #print(\"Done = \", done)\n",
    "    if done:\n",
    "        observation = info[procIdx][\"terminal_observation\"]\n",
    "    \n",
    "    addPar = observation[:,:,shp[2]-1]    \n",
    "    addPar = np.reshape(addPar, (-1))\n",
    "    addPar = addPar[1:additionalPar+1]\n",
    "    actions = addPar[0:additionalPar-nScalarAddPar-2*nChars]\n",
    "        \n",
    "    limAct = [actBufLen * n_actions[0], \n",
    "              actBufLen * n_actions[0] + actBufLen * n_actions[1]]\n",
    "        \n",
    "    moveActionsP1   = actions[0:limAct[0]]\n",
    "    attackActionsP1 = actions[limAct[0]:limAct[1]]\n",
    "    moveActionsP1   = np.reshape(moveActionsP1, (actBufLen,-1))\n",
    "    attackActionsP1 = np.reshape(attackActionsP1, (actBufLen,-1))\n",
    "    print(\"Move actions P1 =\\n\", moveActionsP1)\n",
    "    print(\"Attack actions P1 =\\n\", attackActionsP1)    \n",
    "        \n",
    "    others = addPar[additionalPar-nScalarAddPar-2*nChars:]\n",
    "    print(\"ownHealth = \", others[0])\n",
    "    print(\"oppHealth = \", others[1])\n",
    "    print(\"ownPosition = \", others[2])\n",
    "    print(\"oppPosition = \", others[3])\n",
    "        \n",
    "    obs = np.array(observation).astype(np.float32)\n",
    "    \n",
    "    for idx in range(shp[2]-1):\n",
    "        cv2.imshow(\"image\"+str(idx), obs[:,:,idx])\n",
    "    \n",
    "    cv2.waitKey()\n",
    " \n",
    "    cumulativeEpRew += reward\n",
    "    \n",
    "    if done:\n",
    "        currNumEp += 1\n",
    "        print(\"Ep. # = \", currNumEp)\n",
    "        print(\"Ep. Cumulative Rew # = \", cumulativeEpRew)\n",
    "        \n",
    "        cumulativeEpRewAll.append(cumulativeEpRew)\n",
    "        cumulativeEpRew = 0.0\n",
    "\n",
    "    if np.any(env.get_attr(\"exhausted\")):\n",
    "        break\n",
    "        \n",
    "print(\"All ep. rewards =\", cumulativeEpRewAll)   \n",
    "print(\"Mean cumulative reward =\", np.mean(cumulativeEpRewAll))    \n",
    "print(\"Std cumulative reward =\", np.std(cumulativeEpRewAll))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

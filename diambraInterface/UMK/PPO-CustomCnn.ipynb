{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameFolder = \"UMK3-MAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import time\n",
    "timeDepSeed = int((time.time()-int(time.time()-0.5))*1000)\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../'))   \n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../../../games',gameFolder))   \n",
    "\n",
    "tensorBoardFolder = \"./ppo2_TB_CustCnn/\"\n",
    "modelFolder = \"ppo2_Model_CustCnn/\"\n",
    "\n",
    "os.makedirs(modelFolder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makeDiambraEnv import *\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from customPolicies.utils import linear_schedule\n",
    "from customPolicies.customCnnPolicy import *\n",
    "\n",
    "from stable_baselines import PPO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/apalmas/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "Env_id =  Train0\n",
      "Continue value =  0\n",
      "Player = P1 , Character = Sektor\n",
      "Noop action N =  14\n",
      "Env_id =  Train1\n",
      "Continue value =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apalmas/anaconda3/envs/diambra/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player = P1 , Character = Sektor\n",
      "Noop action N =  14\n",
      "Env_id =  Train2\n",
      "Continue value =  0\n",
      "Player = P1 , Character = Sektor\n",
      "Noop action N =  14\n",
      "Env_id =  Train3\n",
      "Continue value =  0\n",
      "Player = P1 , Character = Sektor\n",
      "Noop action N =  14\n"
     ]
    }
   ],
   "source": [
    "diambraKwargs = {}\n",
    "diambraKwargs[\"roms_path\"] = \"../../../roms/MAMEToolkit/roms/\"\n",
    "diambraKwargs[\"binary_path\"] = \"../../../../customMAME/\"\n",
    "diambraKwargs[\"player\"] = \"P1\"\n",
    "diambraKwargs[\"frame_ratio\"] = 3\n",
    "diambraKwargs[\"render\"] = False\n",
    "#diambraKwargs[\"throttle\"] = False\n",
    "#diambraKwargs[\"sound\"] = False \n",
    "#diambraKwargs[\"character\"] =\"Random\"\n",
    "diambraKwargs[\"character\"] = \"Sektor\"\n",
    "\n",
    "wrapperKwargs = {}\n",
    "wrapperKwargs[\"hwc_obs_resize\"] = [256, 256, 1]\n",
    "wrapperKwargs[\"normalize_rewards\"] = True\n",
    "wrapperKwargs[\"clip_rewards\"] = False\n",
    "wrapperKwargs[\"frame_stack\"] = 6\n",
    "wrapperKwargs[\"scale\"] = True\n",
    "wrapperKwargs[\"scale_mod\"] = 0\n",
    "\n",
    "\n",
    "#keyToAdd = None\n",
    "keyToAdd = []\n",
    "keyToAdd.append(\"actionsBuf\")\n",
    "#keyToAdd.append(\"player\")\n",
    "keyToAdd.append(\"healthP1\")\n",
    "keyToAdd.append(\"healthP2\")\n",
    "keyToAdd.append(\"positionP1\")\n",
    "keyToAdd.append(\"positionP2\")\n",
    "#keyToAdd.append(\"winsP1\")\n",
    "#keyToAdd.append(\"winsP2\")\n",
    "\n",
    "numEnv=4\n",
    "\n",
    "env = make_diambra_env(diambraMame, env_prefix=\"Train\", num_env=numEnv, seed=timeDepSeed, \n",
    "                       continue_game=0, diambra_kwargs=diambraKwargs, \n",
    "                       wrapper_kwargs=wrapperKwargs, key_to_add=keyToAdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs_space =  Box(256, 256, 7)\n",
      "Obs_space type =  float32\n",
      "Obs_space high =  [[[1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]]]\n",
      "Obs_space low =  [[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Obs_space = \", env.observation_space)\n",
    "print(\"Obs_space type = \", env.observation_space.dtype)\n",
    "print(\"Obs_space high = \", env.observation_space.high)\n",
    "print(\"Obs_space low = \", env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Act_space =  Discrete(15)\n",
      "Act_space type =  int64\n",
      "Act_space n =  15\n"
     ]
    }
   ],
   "source": [
    "print(\"Act_space = \", env.action_space)\n",
    "print(\"Act_space type = \", env.action_space.dtype)\n",
    "print(\"Act_space n = \", env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/apalmas/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/apalmas/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/apalmas/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/apalmas/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/apalmas/Applications/Diambra/diambraengine/stableBaselines/diambraInterface/UMK/../customPolicies/customCnnPolicy.py:31: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2729a61ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2729a61ac8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2729a61ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2729a61ac8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2728973390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2728973390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2728973390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2728973390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/apalmas/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/apalmas/anaconda3/envs/diambra/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/apalmas/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/apalmas/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Policy param\n",
    "policyKwargs={}\n",
    "policyKwargs[\"n_add_info\"] = 184\n",
    "policyKwargs[\"layers\"] = [64, 64]\n",
    "\n",
    "# Initialize the model, 1 env\n",
    "model = PPO2(CustCnnPolicy, env, verbose=1, \n",
    "             gamma = 0.94, nminibatches=4, noptepochs=4, n_steps=128,\n",
    "             learning_rate=linear_schedule(2.5e-4, 2.5e-5), cliprange=linear_schedule(0.2, 0.1),\n",
    "             tensorboard_log=tensorBoardFolder, policy_kwargs=policyKwargs)\n",
    "\n",
    "#OR\n",
    "\n",
    "# Load the trained agent, 1 env\n",
    "#model = PPO2.load(modelFolder+\"4_5Msteps_action+_add\", env=env, tensorboard_log=tensorBoardFolder, \n",
    "#                  policy_kwargs=policyKwargs, gamma = 0.94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/apalmas/anaconda3/envs/diambra/lib/python3.6/site-packages/stable_baselines/common/base_class.py:1143: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Setting difficulty = 4\n",
      "Starting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "Setting difficulty = 4\n",
      "Starting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "Setting difficulty = 4\n",
      "Starting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "Setting difficulty = 4\n",
      "Starting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00020415732 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -2.46         |\n",
      "| fps                | 9             |\n",
      "| n_updates          | 1             |\n",
      "| policy_entropy     | 2.7078543     |\n",
      "| policy_loss        | -0.0034307693 |\n",
      "| serial_timesteps   | 128           |\n",
      "| time_elapsed       | 2.17e-05      |\n",
      "| total_timesteps    | 512           |\n",
      "| value_loss         | 1.2586591     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0003751993  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.96         |\n",
      "| fps                | 26            |\n",
      "| n_updates          | 2             |\n",
      "| policy_entropy     | 2.7068045     |\n",
      "| policy_loss        | -0.0050452715 |\n",
      "| serial_timesteps   | 256           |\n",
      "| time_elapsed       | 55.3          |\n",
      "| total_timesteps    | 1024          |\n",
      "| value_loss         | 0.009931405   |\n",
      "--------------------------------------\n",
      "Round done\n",
      "-------------------------------------\n",
      "| approxkl           | 0.008078121  |\n",
      "| clipfrac           | 0.13671875   |\n",
      "| explained_variance | -1.61        |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 3            |\n",
      "| policy_entropy     | 2.69055      |\n",
      "| policy_loss        | -0.015460875 |\n",
      "| serial_timesteps   | 384          |\n",
      "| time_elapsed       | 74.4         |\n",
      "| total_timesteps    | 1536         |\n",
      "| value_loss         | 0.008047839  |\n",
      "-------------------------------------\n",
      "Round done\n",
      "Round done\n",
      "Round done\n",
      "-------------------------------------\n",
      "| approxkl           | 0.003048268  |\n",
      "| clipfrac           | 0.018554688  |\n",
      "| explained_variance | -1.19        |\n",
      "| fps                | 21           |\n",
      "| n_updates          | 4            |\n",
      "| policy_entropy     | 2.697033     |\n",
      "| policy_loss        | -0.008122452 |\n",
      "| serial_timesteps   | 512          |\n",
      "| time_elapsed       | 94.5         |\n",
      "| total_timesteps    | 2048         |\n",
      "| value_loss         | 0.0069675297 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0060891206 |\n",
      "| clipfrac           | 0.07373047   |\n",
      "| explained_variance | -0.948       |\n",
      "| fps                | 23           |\n",
      "| n_updates          | 5            |\n",
      "| policy_entropy     | 2.677452     |\n",
      "| policy_loss        | -0.01073515  |\n",
      "| serial_timesteps   | 640          |\n",
      "| time_elapsed       | 118          |\n",
      "| total_timesteps    | 2560         |\n",
      "| value_loss         | 0.008325068  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0014250245 |\n",
      "| clipfrac           | 0.0053710938 |\n",
      "| explained_variance | -1.29        |\n",
      "| fps                | 23           |\n",
      "| n_updates          | 6            |\n",
      "| policy_entropy     | 2.690935     |\n",
      "| policy_loss        | -0.008426617 |\n",
      "| serial_timesteps   | 768          |\n",
      "| time_elapsed       | 140          |\n",
      "| total_timesteps    | 3072         |\n",
      "| value_loss         | 0.004023815  |\n",
      "-------------------------------------\n",
      "Episode done\n",
      "Restarting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "Episode done\n",
      "Restarting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "------------------------------------\n",
      "| approxkl           | 0.008128481 |\n",
      "| clipfrac           | 0.11767578  |\n",
      "| ep_len_mean        | 853         |\n",
      "| ep_reward_mean     | -3.08       |\n",
      "| explained_variance | -0.991      |\n",
      "| fps                | 14          |\n",
      "| n_updates          | 7           |\n",
      "| policy_entropy     | 2.6769934   |\n",
      "| policy_loss        | -0.02021919 |\n",
      "| serial_timesteps   | 896         |\n",
      "| time_elapsed       | 161         |\n",
      "| total_timesteps    | 3584        |\n",
      "| value_loss         | 0.005020562 |\n",
      "------------------------------------\n",
      "Episode done\n",
      "Restarting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "--------------------------------------\n",
      "| approxkl           | 0.004774094   |\n",
      "| clipfrac           | 0.05126953    |\n",
      "| ep_len_mean        | 896           |\n",
      "| ep_reward_mean     | -2.65         |\n",
      "| explained_variance | -0.937        |\n",
      "| fps                | 14            |\n",
      "| n_updates          | 8             |\n",
      "| policy_entropy     | 2.6659818     |\n",
      "| policy_loss        | -0.0136596495 |\n",
      "| serial_timesteps   | 1024          |\n",
      "| time_elapsed       | 198           |\n",
      "| total_timesteps    | 4096          |\n",
      "| value_loss         | 0.0051663104  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.008340965  |\n",
      "| clipfrac           | 0.13623047   |\n",
      "| ep_len_mean        | 896          |\n",
      "| ep_reward_mean     | -2.65        |\n",
      "| explained_variance | -1.31        |\n",
      "| fps                | 23           |\n",
      "| n_updates          | 9            |\n",
      "| policy_entropy     | 2.6536887    |\n",
      "| policy_loss        | -0.024131764 |\n",
      "| serial_timesteps   | 1152         |\n",
      "| time_elapsed       | 233          |\n",
      "| total_timesteps    | 4608         |\n",
      "| value_loss         | 0.004365228  |\n",
      "-------------------------------------\n",
      "Episode done\n",
      "Restarting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "Round done\n",
      "-------------------------------------\n",
      "| approxkl           | 0.009003595  |\n",
      "| clipfrac           | 0.11669922   |\n",
      "| ep_len_mean        | 978          |\n",
      "| ep_reward_mean     | -2.85        |\n",
      "| explained_variance | -1.46        |\n",
      "| fps                | 10           |\n",
      "| n_updates          | 10           |\n",
      "| policy_entropy     | 2.6297314    |\n",
      "| policy_loss        | -0.025817292 |\n",
      "| serial_timesteps   | 1280         |\n",
      "| time_elapsed       | 255          |\n",
      "| total_timesteps    | 5120         |\n",
      "| value_loss         | 0.0038505495 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.009191714  |\n",
      "| clipfrac           | 0.13330078   |\n",
      "| ep_len_mean        | 978          |\n",
      "| ep_reward_mean     | -2.85        |\n",
      "| explained_variance | -0.681       |\n",
      "| fps                | 16           |\n",
      "| n_updates          | 11           |\n",
      "| policy_entropy     | 2.6136358    |\n",
      "| policy_loss        | -0.026251443 |\n",
      "| serial_timesteps   | 1408         |\n",
      "| time_elapsed       | 302          |\n",
      "| total_timesteps    | 5632         |\n",
      "| value_loss         | 0.0043092775 |\n",
      "-------------------------------------\n",
      "Round done\n",
      "Round done\n",
      "-------------------------------------\n",
      "| approxkl           | 0.008450666  |\n",
      "| clipfrac           | 0.122558594  |\n",
      "| ep_len_mean        | 978          |\n",
      "| ep_reward_mean     | -2.85        |\n",
      "| explained_variance | -0.607       |\n",
      "| fps                | 18           |\n",
      "| n_updates          | 12           |\n",
      "| policy_entropy     | 2.5954998    |\n",
      "| policy_loss        | -0.027711734 |\n",
      "| serial_timesteps   | 1536         |\n",
      "| time_elapsed       | 333          |\n",
      "| total_timesteps    | 6144         |\n",
      "| value_loss         | 0.004524387  |\n",
      "-------------------------------------\n",
      "Round done\n",
      "-------------------------------------\n",
      "| approxkl           | 0.009956181  |\n",
      "| clipfrac           | 0.15966797   |\n",
      "| ep_len_mean        | 978          |\n",
      "| ep_reward_mean     | -2.85        |\n",
      "| explained_variance | -0.675       |\n",
      "| fps                | 13           |\n",
      "| n_updates          | 13           |\n",
      "| policy_entropy     | 2.6065688    |\n",
      "| policy_loss        | -0.026868451 |\n",
      "| serial_timesteps   | 1664         |\n",
      "| time_elapsed       | 361          |\n",
      "| total_timesteps    | 6656         |\n",
      "| value_loss         | 0.0042202612 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.011054791  |\n",
      "| clipfrac           | 0.17919922   |\n",
      "| ep_len_mean        | 978          |\n",
      "| ep_reward_mean     | -2.85        |\n",
      "| explained_variance | -0.0993      |\n",
      "| fps                | 23           |\n",
      "| n_updates          | 14           |\n",
      "| policy_entropy     | 2.579863     |\n",
      "| policy_loss        | -0.034061413 |\n",
      "| serial_timesteps   | 1792         |\n",
      "| time_elapsed       | 400          |\n",
      "| total_timesteps    | 7168         |\n",
      "| value_loss         | 0.003781839  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode done\n",
      "Restarting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "Episode done\n",
      "Restarting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "-------------------------------------\n",
      "| approxkl           | 0.009885879  |\n",
      "| clipfrac           | 0.14208984   |\n",
      "| ep_len_mean        | 905          |\n",
      "| ep_reward_mean     | -3           |\n",
      "| explained_variance | -0.0927      |\n",
      "| fps                | 13           |\n",
      "| n_updates          | 15           |\n",
      "| policy_entropy     | 2.5619233    |\n",
      "| policy_loss        | -0.034709673 |\n",
      "| serial_timesteps   | 1920         |\n",
      "| time_elapsed       | 422          |\n",
      "| total_timesteps    | 7680         |\n",
      "| value_loss         | 0.0038883367 |\n",
      "-------------------------------------\n",
      "Episode done\n",
      "Restarting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "-------------------------------------\n",
      "| approxkl           | 0.011432188  |\n",
      "| clipfrac           | 0.17089844   |\n",
      "| ep_len_mean        | 950          |\n",
      "| ep_reward_mean     | -3.03        |\n",
      "| explained_variance | -0.473       |\n",
      "| fps                | 18           |\n",
      "| n_updates          | 16           |\n",
      "| policy_entropy     | 2.5616007    |\n",
      "| policy_loss        | -0.045049097 |\n",
      "| serial_timesteps   | 2048         |\n",
      "| time_elapsed       | 459          |\n",
      "| total_timesteps    | 8192         |\n",
      "| value_loss         | 0.0053057233 |\n",
      "-------------------------------------\n",
      "Episode done\n",
      "Restarting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "Round done\n",
      "-------------------------------------\n",
      "| approxkl           | 0.014325489  |\n",
      "| clipfrac           | 0.1953125    |\n",
      "| ep_len_mean        | 971          |\n",
      "| ep_reward_mean     | -2.92        |\n",
      "| explained_variance | -1.09        |\n",
      "| fps                | 16           |\n",
      "| n_updates          | 17           |\n",
      "| policy_entropy     | 2.5780609    |\n",
      "| policy_loss        | -0.036967076 |\n",
      "| serial_timesteps   | 2176         |\n",
      "| time_elapsed       | 488          |\n",
      "| total_timesteps    | 8704         |\n",
      "| value_loss         | 0.004859211  |\n",
      "-------------------------------------\n",
      "Round done\n",
      "-------------------------------------\n",
      "| approxkl           | 0.011166511  |\n",
      "| clipfrac           | 0.16992188   |\n",
      "| ep_len_mean        | 971          |\n",
      "| ep_reward_mean     | -2.92        |\n",
      "| explained_variance | -0.296       |\n",
      "| fps                | 23           |\n",
      "| n_updates          | 18           |\n",
      "| policy_entropy     | 2.5636497    |\n",
      "| policy_loss        | -0.040871274 |\n",
      "| serial_timesteps   | 2304         |\n",
      "| time_elapsed       | 519          |\n",
      "| total_timesteps    | 9216         |\n",
      "| value_loss         | 0.0040798374 |\n",
      "-------------------------------------\n",
      "Round done\n",
      "-------------------------------------\n",
      "| approxkl           | 0.013556276  |\n",
      "| clipfrac           | 0.19970703   |\n",
      "| ep_len_mean        | 971          |\n",
      "| ep_reward_mean     | -2.92        |\n",
      "| explained_variance | -0.581       |\n",
      "| fps                | 23           |\n",
      "| n_updates          | 19           |\n",
      "| policy_entropy     | 2.5636659    |\n",
      "| policy_loss        | -0.045479257 |\n",
      "| serial_timesteps   | 2432         |\n",
      "| time_elapsed       | 541          |\n",
      "| total_timesteps    | 9728         |\n",
      "| value_loss         | 0.004524843  |\n",
      "-------------------------------------\n",
      "Episode done\n",
      "Restarting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "Episode done\n",
      "Restarting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "-------------------------------------\n",
      "| approxkl           | 0.01940254   |\n",
      "| clipfrac           | 0.27783203   |\n",
      "| ep_len_mean        | 893          |\n",
      "| ep_reward_mean     | -3.04        |\n",
      "| explained_variance | 0.0374       |\n",
      "| fps                | 13           |\n",
      "| n_updates          | 20           |\n",
      "| policy_entropy     | 2.5915816    |\n",
      "| policy_loss        | -0.026030038 |\n",
      "| serial_timesteps   | 2560         |\n",
      "| time_elapsed       | 563          |\n",
      "| total_timesteps    | 10240        |\n",
      "| value_loss         | 0.012196597  |\n",
      "-------------------------------------\n",
      "Round done\n",
      "-------------------------------------\n",
      "| approxkl           | 0.014509115  |\n",
      "| clipfrac           | 0.2163086    |\n",
      "| ep_len_mean        | 893          |\n",
      "| ep_reward_mean     | -3.04        |\n",
      "| explained_variance | -0.127       |\n",
      "| fps                | 23           |\n",
      "| n_updates          | 21           |\n",
      "| policy_entropy     | 2.5609047    |\n",
      "| policy_loss        | -0.04444384  |\n",
      "| serial_timesteps   | 2688         |\n",
      "| time_elapsed       | 601          |\n",
      "| total_timesteps    | 10752        |\n",
      "| value_loss         | 0.0042976597 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.012906697  |\n",
      "| clipfrac           | 0.20117188   |\n",
      "| ep_len_mean        | 893          |\n",
      "| ep_reward_mean     | -3.04        |\n",
      "| explained_variance | -0.875       |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 22           |\n",
      "| policy_entropy     | 2.5287716    |\n",
      "| policy_loss        | -0.045422215 |\n",
      "| serial_timesteps   | 2816         |\n",
      "| time_elapsed       | 622          |\n",
      "| total_timesteps    | 11264        |\n",
      "| value_loss         | 0.0036858006 |\n",
      "-------------------------------------\n",
      "Episode done\n",
      "Restarting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "-------------------------------------\n",
      "| approxkl           | 0.017252618  |\n",
      "| clipfrac           | 0.24609375   |\n",
      "| ep_len_mean        | 902          |\n",
      "| ep_reward_mean     | -3.06        |\n",
      "| explained_variance | -0.785       |\n",
      "| fps                | 17           |\n",
      "| n_updates          | 23           |\n",
      "| policy_entropy     | 2.5235877    |\n",
      "| policy_loss        | -0.047439575 |\n",
      "| serial_timesteps   | 2944         |\n",
      "| time_elapsed       | 643          |\n",
      "| total_timesteps    | 11776        |\n",
      "| value_loss         | 0.0046266895 |\n",
      "-------------------------------------\n",
      "Round done\n",
      "Round done\n",
      "-------------------------------------\n",
      "| approxkl           | 0.01711223   |\n",
      "| clipfrac           | 0.22363281   |\n",
      "| ep_len_mean        | 902          |\n",
      "| ep_reward_mean     | -3.06        |\n",
      "| explained_variance | -0.55        |\n",
      "| fps                | 22           |\n",
      "| n_updates          | 24           |\n",
      "| policy_entropy     | 2.5489132    |\n",
      "| policy_loss        | -0.044992518 |\n",
      "| serial_timesteps   | 3072         |\n",
      "| time_elapsed       | 671          |\n",
      "| total_timesteps    | 12288        |\n",
      "| value_loss         | 0.004862744  |\n",
      "-------------------------------------\n",
      "Episode done\n",
      "Restarting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "-------------------------------------\n",
      "| approxkl           | 0.01705443   |\n",
      "| clipfrac           | 0.24169922   |\n",
      "| ep_len_mean        | 917          |\n",
      "| ep_reward_mean     | -3.07        |\n",
      "| explained_variance | -0.659       |\n",
      "| fps                | 17           |\n",
      "| n_updates          | 25           |\n",
      "| policy_entropy     | 2.5230465    |\n",
      "| policy_loss        | -0.044788107 |\n",
      "| serial_timesteps   | 3200         |\n",
      "| time_elapsed       | 694          |\n",
      "| total_timesteps    | 12800        |\n",
      "| value_loss         | 0.004269041  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.016166138  |\n",
      "| clipfrac           | 0.24560547   |\n",
      "| ep_len_mean        | 917          |\n",
      "| ep_reward_mean     | -3.07        |\n",
      "| explained_variance | -0.297       |\n",
      "| fps                | 25           |\n",
      "| n_updates          | 26           |\n",
      "| policy_entropy     | 2.504693     |\n",
      "| policy_loss        | -0.047835715 |\n",
      "| serial_timesteps   | 3328         |\n",
      "| time_elapsed       | 723          |\n",
      "| total_timesteps    | 13312        |\n",
      "| value_loss         | 0.0039099744 |\n",
      "-------------------------------------\n",
      "Episode done\n",
      "Restarting game\n",
      "Selecting Sektor\n",
      "Waiting for fight to start\n",
      "Round done\n",
      "-------------------------------------\n",
      "| approxkl           | 0.016664546  |\n",
      "| clipfrac           | 0.17871094   |\n",
      "| ep_len_mean        | 911          |\n",
      "| ep_reward_mean     | -3.09        |\n",
      "| explained_variance | -0.274       |\n",
      "| fps                | 17           |\n",
      "| n_updates          | 27           |\n",
      "| policy_entropy     | 2.5014923    |\n",
      "| policy_loss        | -0.046545014 |\n",
      "| serial_timesteps   | 3456         |\n",
      "| time_elapsed       | 743          |\n",
      "| total_timesteps    | 13824        |\n",
      "| value_loss         | 0.004389993  |\n",
      "-------------------------------------\n",
      "Round done\n",
      "------------------------------------\n",
      "| approxkl           | 0.016961802 |\n",
      "| clipfrac           | 0.25048828  |\n",
      "| ep_len_mean        | 911         |\n",
      "| ep_reward_mean     | -3.09       |\n",
      "| explained_variance | -0.691      |\n",
      "| fps                | 24          |\n",
      "| n_updates          | 28          |\n",
      "| policy_entropy     | 2.4679356   |\n",
      "| policy_loss        | -0.05515437 |\n",
      "| serial_timesteps   | 3584        |\n",
      "| time_elapsed       | 773         |\n",
      "| total_timesteps    | 14336       |\n",
      "| value_loss         | 0.005243414 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the agent\n",
    "time_steps = 20000000\n",
    "model.learn(total_timesteps=time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the agent\n",
    "model.save(modelFolder+\"5_8Msteps_action+_add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "states = None\n",
    "\n",
    "while True:\n",
    "\n",
    "    action, states = model.predict(observation, states, deterministic=False)\n",
    "    action_prob = model.action_probability(observation, states)\n",
    "    print(\"Action probabilities = \", action_prob)\n",
    "    print(\"Max action = \", np.argmax(action_prob))\n",
    "    print(\"Action = \", action)\n",
    "    input(\"Pausa\")\n",
    "    \n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "        states = None\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "states = None\n",
    "\n",
    "cumulativeEpRew = 0.0\n",
    "cumulativeEpRewAll = []\n",
    "cumulativeTotRew = 0.0\n",
    "\n",
    "maxNumEp = 100\n",
    "currNumEp = 0\n",
    "\n",
    "while currNumEp < maxNumEp:\n",
    "\n",
    "    action, states = model.predict(observation, states, deterministic=False)\n",
    "    action_prob = model.action_probability(observation, states)\n",
    "    print(\"Action probabilities = \", action_prob)\n",
    "    print(\"Max action = \", np.argmax(action_prob))\n",
    "    print(\"Action = \", action)\n",
    "    \n",
    "    observation, reward, done, info = env.step(action)\n",
    "    \n",
    "    cumulativeEpRew += reward\n",
    "    \n",
    "    if np.any(done):\n",
    "        currNumEp += 1\n",
    "        print(\"Ep. # = \", currNumEp)\n",
    "        print(\"Ep. Cumulative Rew # = \", cumulativeEpRew)\n",
    "        sys.stdout.flush()\n",
    "        cumulativeEpRewAll.append(cumulativeEpRew)\n",
    "        cumulativeTotRew += cumulativeEpRew\n",
    "        cumulativeEpRew = 0.0\n",
    "\n",
    "        observation = env.reset()\n",
    "        states = None\n",
    "\n",
    "print(\"Mean cumulative reward = \", cumulativeTotRew/maxNumEp)    \n",
    "print(\"Mean cumulative reward = \", np.mean(cumulativeEpRewAll))    \n",
    "print(\"Std cumulative reward = \", np.std(cumulativeEpRewAll))   \n",
    "    \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
